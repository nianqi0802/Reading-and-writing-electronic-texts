{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This week I began my work by analyzing a short paragraph I wrote four years ago. It looks like this: \n",
    "\n",
    "杏黄的叶子  \n",
    "落下也是一棵树的荒魂  \n",
    "一生不曾见过鲜花的脸颊与荆棘  \n",
    "却要衔着血脉里危险的爱意  \n",
    "神交到泥土中去  \n",
    "\n",
    "Yellow apricot leaf  \n",
    "falled from the tree.  \n",
    "Never have it met the cheek of flower or thorns in life.  \n",
    "But with the dangerous love in blood,   \n",
    "it mates with the mud.  \n",
    "  \n",
    "(It's still hard to translate for me and the above works as a reference)  \n",
    "\n",
    "### I reorganized the paragraph and cut some words to make it more like a poem. \n",
    "\n",
    "Yellow apricot leaf  \n",
    "falled from the tree.  \n",
    "\"I never see the cheek of flower in my life.\"  \n",
    "It says,  \n",
    "and mates with the mud.  \n",
    "  \n",
    "### Then I tried to decide what part of words should be replaced by strict randomness or crazy randomness. It was quite struggle as from the assignment before, the crazy randomness of words was actually working pretty well. But it's hard for them to convey specific idea or logic. \n",
    "\n",
    "### So I turn the main characters into crazy random words from a big  words library where words do not have a connection in meaning. And for the verbs that act as the connection point, I made my own lists which contains some words that have similar meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery \n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracery.modifiers import base_english\n",
    "from translate import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = open(\"adj.txt\").read().split(\"\\n\")\n",
    "verb = open(\"verb.txt\").read().split(\"\\n\")\n",
    "noun = open(\"nounlist.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodypart = json.load(open(\"bodyParts.json\"))\n",
    "verb_2 = json.load(open(\"verbs.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow apricot leaf\n",
      "falled from the tree.\n",
      "\"I never see the cheek of flower in my life.\"\n",
      "It says,\n",
      "and mates with the mud.\n",
      "\n",
      "\n",
      "杏杏叶从树上落下。 “我生命中从未见过花的脸颊。”它说，并与泥浆交配。\n"
     ]
    }
   ],
   "source": [
    "#my original one poem\n",
    "\n",
    "# rules ={\n",
    "#     \"origin\" : [\"#lineone#\\n#linetwo#.\\n#linethree#\\n#linefour#\\n#linefive#\"],\n",
    "    \n",
    "# #     \"title\":[\"For the #somewhere.capitalize#\"],\n",
    "    \n",
    "#     \"lineone\":[\"#adj.capitalize# #adj# #main#\"],\n",
    "    \n",
    "#     \"linetwo\":[\"#done.ed# from the #somewhere#\"],\n",
    "    \n",
    "#     \"linethree\":[\"\\\"I never #do# the #sth# of #ofsth# in my life.\\\"\"],\n",
    "    \n",
    "#     \"linefour\":[\"#he.capitalize# says,\"],\n",
    "    \n",
    "#     \"linefive\":[\"and #dowith.s# with the #someone#.\"],\n",
    "    \n",
    "    \n",
    "#     \"adj\" : [\n",
    "#         \"apricot\",\n",
    "#          \"yellow\"\n",
    "#     ],\n",
    "   \n",
    "#     \"main\":[\n",
    "#         \"leaf\"\n",
    "#     ],\n",
    "    \n",
    "#     \"done\" :[\n",
    "#         \"fall\"\n",
    "#     ],\n",
    "#     \"somewhere\":[\n",
    "#         \"tree\"\n",
    "#     ],\n",
    "    \n",
    "#      \"do\" :[\n",
    "#         \"see\"\n",
    "#     ],\n",
    "#     \"sth\":[\n",
    "#         \"cheek\"\n",
    "#     ],\n",
    "    \n",
    "#      \"ofsth\" :[\n",
    "#         \"flower\"\n",
    "#     ],\n",
    "    \n",
    "    \n",
    "#     \"he\":[\n",
    "#         \"she\",\n",
    "#         \"he\",\n",
    "#         \"it\"\n",
    "#     ],\n",
    "    \n",
    "#     \"dowith\":[\n",
    "#         \"mate\"\n",
    "#     ],\n",
    "    \n",
    "#     \"someone\":[\n",
    "#         \"mud\"\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "# }\n",
    "\n",
    "# grammar = tracery.Grammar(rules)\n",
    "# grammar.add_modifiers(base_english)\n",
    "\n",
    "# from translate import Translator\n",
    "\n",
    "# text = grammar.flatten(\"#origin#\")\n",
    "# translator= Translator(to_lang=\"zh\")\n",
    "# translation = translator.translate(text)\n",
    "\n",
    "# print(grammar.flatten(\"#origin#\"))\n",
    "# print(\"\\n\")\n",
    "# print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from translate import Translator\n",
    "\n",
    "# text = grammar.flatten(\"#origin#\")\n",
    "# translator= Translator(to_lang=\"zh\")\n",
    "# translation = translator.translate(text)\n",
    "# print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impolite overcooked lipstick\n",
      "dimed from the request.\n",
      "\"I never handle the head of request in my life.\"\n",
      "He says,\n",
      "and replaces with the termination.\n",
      "\n",
      "\n",
      "MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  15 HOURS 52 MINUTES 28 SECONDSVISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules ={\n",
    "    \"origin\" : [\"#lineone#\\n#linetwo#.\\n#linethree#\\n#linefour#\\n#linefive#\"],\n",
    "    \n",
    "#     \"title\":[\"For the #somewhere.capitalize#\"],\n",
    "    \n",
    "    \"lineone\":[\"#adjone.capitalize# #adjtwo# #main#\"],\n",
    "    \n",
    "    \"linetwo\":[\"#done.ed# from the #somewhere#\"],\n",
    "    \n",
    "    \"linethree\":[\"\\\"I never #do# the #sth# of #somewhere# in my life.\\\"\"],\n",
    "    \n",
    "    \"linefour\":[\"#he.capitalize# says,\"],\n",
    "    \n",
    "    \"linefive\":[\"and #dowith.s# with the #someone#.\"],\n",
    "    \n",
    "    \n",
    "    \"adjone\" : [\n",
    "       random.choice(adj)\n",
    "    ],\n",
    "   \n",
    "    \"adjtwo\":[\n",
    "        random.choice(adj)\n",
    "    ],\n",
    "    \n",
    "     \"main\":[\n",
    "        random.choice(noun)\n",
    "    ],\n",
    "    \n",
    "    \"done\" :[\n",
    "        \"fall\",\n",
    "        \"dime\",\n",
    "        \"leave\",\n",
    "        \"depart\",\n",
    "        \"quit\",\n",
    "        \"disappear\"\n",
    "    ],\n",
    "    \"somewhere\":[\n",
    "       random.choice(noun)\n",
    "    ],\n",
    "    \n",
    "     \"do\" :[\n",
    "        random.choice(verb_2['verbs'])['present']\n",
    "     ],\n",
    "         \n",
    "    \"sth\":[\n",
    "        random.choice(bodypart['bodyParts'])\n",
    "    ],\n",
    "    \n",
    "     \"ofsth\" :[\n",
    "        \"flower\"\n",
    "    ],\n",
    "    \n",
    "    \n",
    "    \"he\":[\n",
    "        \"she\",\n",
    "        \"he\",\n",
    "        \"it\"\n",
    "    ],\n",
    "    \n",
    "    \"dowith\":[\n",
    "#         \"date\",\n",
    "#         \"mate\",\n",
    "#         \"dance\",\n",
    "#         \"sing\",\n",
    "        random.choice(verb_2['verbs'])['present']\n",
    "    ],\n",
    "    \n",
    "    \"someone\":[\n",
    "       random.choice(noun)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "text = grammar.flatten(\"#origin#\")\n",
    "translator= Translator(to_lang=\"zh\")\n",
    "translation = translator.translate(text)\n",
    "print(grammar.flatten(\"#origin#\"))\n",
    "print(\"\\n\")\n",
    "print(translation)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some outputs: \n",
    "\n",
    "Adorable neighboring scallion  \n",
    "dimed from the lily.  \n",
    "\"I never pinch the foot of lily in my life.\"  \n",
    "He says,  \n",
    "and reigns with the reader.  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "Immaterial flowery fortress  \n",
    "quited from the astronomy.  \n",
    "\"I never improve the toe of astronomy in my life.\"  \n",
    "It says,  \n",
    "and branches with the mid-course.  \n",
    "  \n",
    "  \n",
    "Scented impressive icy  \n",
    "falled from the relative.  \n",
    "\"I never suspend the ankle of relative in my life.\"  \n",
    "She says,  \n",
    "and fills with the dentist.  \n",
    "  \n",
    "  \n",
    "Original petty humor  \n",
    "falled from the exhibition.  \n",
    "\"I never unfasten the bottom of exhibition in my life.\"  \n",
    "She says,  \n",
    "and admits with the alpaca.  \n",
    "   \n",
    "\n",
    "Self-reliant tall commodity  \n",
    "falled from the cartel.\n",
    "\"I never pine the upper arm of cartel in my life.\"  \n",
    "It says,  \n",
    "and explains with the uplift.  \n",
    "\n",
    "(this one is actually very interesting as the word 'pine' works with never to make a positve sentence)  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

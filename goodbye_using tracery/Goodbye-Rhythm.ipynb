{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx in /Users/nianqi/anaconda3/lib/python3.6/site-packages (1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery \n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tracery.modifiers import base_english\n",
    "from translate import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = open(\"adj.txt\").read().split(\"\\n\")\n",
    "verb = open(\"verb.txt\").read().split(\"\\n\")\n",
    "noun = open(\"nounlist.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodypart = json.load(open(\"bodyParts.json\"))\n",
    "verb_2 = json.load(open(\"verbs.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = random.choice(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sponsor'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findrhythm(lists):\n",
    "    wordout = []\n",
    "    for words in lists:\n",
    "        if (words in pr.rhymes(main)):\n",
    "             wordout.append(words)\n",
    "        return wordout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findrhythm(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I first try with the function above, but it seems to be too hard to find a rhythm word in this way. So I have to change my strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhymeslist = pr.rhymes(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bonser', 'conser', 'gonser', 'hanser', 'monsour']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhymeslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "strlist = ' '.join(rhymeslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlplist = nlp(strlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounlist = []\n",
    "for word in nlplist:\n",
    "    if(word.pos_ == \"NOUN\"):\n",
    "        nounlist.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "someone = random.choice(nounlist)\n",
    "somewhere = random.choice(nounlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnest studious sponsor\n",
      "quited from the hanser.\n",
      "\"I never hand the waist of the hanser in my life.\" \n",
      "He says,\n",
      "and tours with the monsour.\n",
      "\n",
      "\n",
      "来自hanser的认真好学的赞助商。 \n",
      "“我从来没有把握住我生命中的腰部。”它说，和monsour一起游览。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules ={\n",
    "    \"origin\" : [\"#lineone#\\n#linetwo#.\\n#linethree#\\n#linefour#\\n#linefive#\"],\n",
    "    \n",
    "#     \"title\":[\"For the #somewhere.capitalize#\"],\n",
    "    \n",
    "    \"lineone\":[\"#adjone.capitalize# #adjtwo# #main#\"],\n",
    "    \n",
    "    \"linetwo\":[\"#done.ed# from the #somewhere#\"],\n",
    "    \n",
    "    \"linethree\":[\"\\\"I never #do# the #sth# of the #somewhere# in my life.\\\" \"],\n",
    "    \n",
    "    \"linefour\":[\"#he.capitalize# says,\"],\n",
    "    \n",
    "    \"linefive\":[\"and #dowith.s# with the #someone#.\"],\n",
    "    \n",
    "    \n",
    "    \"adjone\" : [\n",
    "       random.choice(adj)\n",
    "    ],\n",
    "   \n",
    "    \"adjtwo\":[\n",
    "        random.choice(adj)\n",
    "    ],\n",
    "    \n",
    "     \"main\":[\n",
    "        main\n",
    "    ],\n",
    "    \n",
    "    \"done\" :[\n",
    "        \"fall\",\n",
    "        \"dime\",\n",
    "        \"leave\",\n",
    "        \"depart\",\n",
    "        \"quit\",\n",
    "        \"disappear\"\n",
    "    ],\n",
    "    \"somewhere\":[\n",
    "       random.choice(rhymeslist)\n",
    "    ],\n",
    "    \n",
    "     \"do\" :[\n",
    "        random.choice(verb_2['verbs'])['present']\n",
    "     ],\n",
    "         \n",
    "    \"sth\":[\n",
    "        random.choice(bodypart['bodyParts'])\n",
    "    ],\n",
    "    \n",
    "     \"ofsth\" :[\n",
    "        \"flower\"\n",
    "    ],\n",
    "    \n",
    "    \n",
    "    \"he\":[\n",
    "        \"she\",\n",
    "        \"he\",\n",
    "        \"it\"\n",
    "    ],\n",
    "    \n",
    "    \"dowith\":[\n",
    "#         \"date\",\n",
    "#         \"mate\",\n",
    "#         \"dance\",\n",
    "#         \"sing\",\n",
    "        random.choice(verb_2['verbs'])['present']\n",
    "    ],\n",
    "    \n",
    "    \"someone\":[\n",
    "       random.choice(rhymeslist)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "text = grammar.flatten(\"#origin#\")\n",
    "translator= Translator(to_lang=\"zh\")\n",
    "translation = translator.translate(text)\n",
    "print(grammar.flatten(\"#origin#\"))\n",
    "print(\"\\n\")\n",
    "print(translation.replace(\" \",\" \\n\"))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some outputs: \n",
    "\n",
    "Enchanting taut clause  \n",
    "departed from the draus.  \n",
    "\"I never hope the mouth of the draus in my life.\"   \n",
    "She says,  \n",
    "and stirs with the baus.  \n",
    "\n",
    "\n",
    "从连续剧中退出了附带的绷紧条款。   \n",
    "“我从来没有希望过我生命中的话题。”它说，并与baus搅拌。  \n",
    "\n",
    "\n",
    "Overcooked agile stomach  \n",
    "disappeared from the cummock.  \n",
    "\"I never damage the ankle of the cummock in my life.\"   \n",
    "It says,  \n",
    "and clears with the cummock.  \n",
    "\n",
    "  \n",
    "煮熟的敏捷胃离开了小丘。    \n",
    "“在我的生活中，我永远不会损坏小丘的脚踝。”她说，并且与小床一起清除。  \n",
    "  \n",
    "\n",
    "Curvy energetic navigation  \n",
    "dimed from the islamization.  \n",
    "\"I never print the chin of the islamization in my life.\"   \n",
    "He says,  \n",
    "and grabs with the correlation.  \n",
    "\n",
    "  \n",
    "弯曲的精力充沛的导航离开了伊斯兰化。   \n",
    "“我从来没有在我的生活中打印过伊斯兰化的下巴。”它说，并抓住相关性。  \n",
    "\n",
    "\n",
    "Earnest studious sponsor  \n",
    "quited from the hanser.  \n",
    "\"I never hand the waist of the hanser in my life.\"   \n",
    "He says,  \n",
    "and tours with the monsour.  \n",
    "\n",
    "\n",
    "来自hanser的认真好学的赞助商。   \n",
    "“我从来没有把握住我生命中的腰部。”它说，和monsour一起游览。  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
